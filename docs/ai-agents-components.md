# AI 에이전트의 구성 요소

## AI 에이전트 인지

AI 에이전트의 인지란 인공 지능(AI) 에이전트가 주변 환경으로부터 데이터를 수집, 해석 및 처리하여 정보를 기반으로 의사 결정을 내리는 능력을 의미합니다.

이는 센서, 데이터 입력 또는 외부 소스를 사용하여 에이전트가 작동하는 시스템의 현재 상태를 이해하는 과정을 포함합니다.

### AI 에이전트 인지 유형

| 인지 유형  | 설명                               | 주요 기술                                 | 활용 사례                    | 특징                     |
|--------|----------------------------------|---------------------------------------|--------------------------|------------------------|
| 시각적 인식 | 이미지·비디오 등 시각 데이터를 통해 환경을 해석하고 반응 | 컴퓨터 비전, 딥 러닝, CNN, Vision Transformer | 자율주행, 의료 영상 분석, 로보틱스, 보안 | 인간 시각을 모방, 객체 인식·장면 이해 |
| 청각적 인식 | 소리와 음성을 처리·이해하여 사용자 및 환경과 상호작용   | ASR, NLP, 딥 러닝, 음성 신경망                | 음성 비서, 접근성 도구, 감시 시스템    | 다양한 억양·소음 환경에서도 인식     |
| 텍스트 인식 | 텍스트를 이해·생성하며 의미와 맥락을 파악          | NLP, LLM, Transformer, NER            | 챗봇, 검색, 문서 분석, 요약        | 의미론적 이해 및 추론 가능        |
| 환경적 인식 | 다중 센서 데이터를 통합해 물리적 환경을 총체적으로 이해  | 센서 융합, 컴퓨팅 비전, 머신 러닝                  | 자율 로봇, 스마트 팩토리, 드론       | 시각·청각을 넘어 물리 세계 전반 인식  |
| 예측적 인식 | 관찰된 데이터를 바탕으로 미래 상태와 변화를 예측      | ML, 딥 러닝, 확률 모델, 강화 학습                | 수요 예측, 장애 예측, 선제적 대응     | 감지 + 예측 결합, 미래 지향적 추론  |

### 에이전트 인지 작동 방식

프로세스는 에이전트의 설계 및 유형에 따라 다르지만, 에이전트의 인식에서 사용되는 기본적인 단계는 다음과 같습니다.

1. 감각 입력 수집
2. 데이터 처리 및 특징 추출
3. 패턴 인식 및 해석
4. 의사 결정 및 대응

### 다양한 유형의 에이전트가 인지하는 방식

| 에이전트 유형           | 인식 방식          | 의사결정 기준            | 기억/학습      | 특징              | 예시                |
|-------------------|----------------|--------------------|------------|-----------------|-------------------|
| 단순 반사 에이전트        | 현재 센서 입력만 인식   | 미리 정의된 규칙(if-then) | 없음         | 즉각 반응, 구조 단순    | 온도 조절기, 단순 자동 제어  |
| 모델 기반 반사 에이전트     | 센서 + 내부 상태 모델  | 규칙 + 내부 모델         | 제한적(상태 유지) | 시간에 따른 환경 변화 추적 | 장애물 회피 로봇         |
| 목표 기반 에이전트        | 센서로 환경 인식      | 목표 달성 여부           | 상태 기반      | 목표 중심 행동 선택     | 경로 탐색 에이전트        |
| 유틸리티 기반 에이전트      | 환경 상태 전반 평가    | 유틸리티 함수 최대화        | 상태 기반      | 최적의 선택 추구       | 자원 최적화 시스템        |
| 학습 에이전트           | 센서 + 과거 경험     | 학습된 정책             | 있음 (적응·개선) | 경험을 통해 성능 향상    | 추천 시스템, 강화학습 에이전트 |
| 다중 에이전트 시스템 (MAS) | 다수 에이전트의 감각 공유 | 분산·협력 의사결정         | 집단 학습      | 확장성·적응성 우수      | 드론 군집, 분산 모니터링    |

## 에이전틱 추론

AI가 “생각만 하는 모델”을 넘어서 스스로 판단 → 계획 → 행동(툴 사용) → 결과를 반영하며 목표를 달성하는 추론 방식입니다.

### 에이전틱 추론 전략

| 추론 전략          | 핵심 개념                           | 장점                | 단점                   | 적합한 사용 사례                     |
|----------------|---------------------------------|-------------------|----------------------|-------------------------------|
| 조건부 논리         | if-then 규칙 기반 추론                | 단순·예측 가능, 구현 용이   | 유연성 부족, 새로운 상황 대응 불가 | 규칙이 명확한 도메인 (사기 탐지, 룰 기반 자동화) |
| 휴리스틱           | 목표 달성을 위한 경험적 규칙·탐색             | 계산 효율적, 빠른 의사결정   | 전역 최적해 보장 어려움        | 경로 탐색, 자원 최적화                 |
| ReAct (이유+행동)  | Think-Act-Observe 반복 루프         | 단계별 추론, 높은 투명성    | 무한 루프 위험, 토큰·비용 증가   | 자연어 추론, 탐색적 문제 해결             |
| ReWOO          | 사전 계획 후 실행 (Plan-Execute-Solve) | 토큰 절감, 안정성 높음     | 환경 변화 대응 약함          | 구조화된 NLP 작업, 비용 민감 환경         |
| 자기 반성 (LATS 등) | 추론 오류를 스스로 평가·수정                | 고품질 결과, 복잡한 문제 해결 | 계산 비용·시간 증가          | 코딩, 웹 탐색, 복잡한 워크플로            |
| 다중 에이전트 추론     | 여러 에이전트 협력·분산 추론                | 확장성, 도메인 전문성 결합   | 오케스트레이션 복잡성          | 복잡한 시스템, 협업 기반 문제             |

### 에이전틱 추론의 과제

| 과제     | 설명                          | 주요 문제점            | 대응 필요 사항                    |
|--------|-----------------------------|-------------------|-----------------------------|
| 계산 복잡성 | 복잡한 추론 과정이 많은 시간과 연산 자원을 요구 | 높은 컴퓨팅 비용, 응답 지연  | 추론 전략 최적화, 인프라 투자           |
| 해석 가능성 | 의사 결정 과정이 불투명해질 수 있음        | 결과 신뢰도 저하, 윤리적 문제 | 설명 가능한 AI(XAI), 인간 감독(HITL) |
| 확장성    | 모든 문제에 동일한 추론 전략 적용 불가      | 재사용 어려움, 개발 비용 증가 | 사용 사례별 맞춤 설계                |

## 메모리

AI 에이전트 기억은 인공 지능(AI) 시스템이 과거 경험을 저장하고 회상하여 의사 결정, 인식 및 전체 성능을 향상시키는 능력을 의미합니다.

기존 AI 모델이 각 작업을 독립적으로 처리하는 것과 달리, 기억을 가진 AI 에이전트는 맥락을 유지하고 시간에 따라 패턴을 인식하며 과거 상호 작용을 기반으로 적응할 수 있습니다.

이러한 기능은 피드백 루프, 지식 기반, 적응형 학습이 필요한 목표 지향형 AI 애플리케이션에서 필수적입니다.

대규모 언어 모델(LLM)은 스스로 정보를 기억할 수 없습니다. 기억 구성 요소를 별도로 추가해야 합니다.

그러나 AI 기억 설계에서 가장 큰 과제 중 하나는 검색 효율성을 최적화하는 것으로 데이터를 과도하게 저장하면 응답 속도가 느려질 수 있습니다.

### 에이전트 기억의 유형

| 기억 유형       | 정의                           | 저장 범위  | 구현 방식             | 주요 활용 사례         | 한계                   |
|-------------|------------------------------|--------|-------------------|------------------|----------------------|
| 단기 기억 (STM) | 즉각적인 의사결정을 위해 최근 입력을 유지하는 기억 | 단일 세션  | 컨텍스트 윈도우, 롤링 버퍼   | 대화형 AI의 문맥 유지    | 세션 종료 시 소멸, 장기 학습 불가 |
| 장기 기억 (LTM) | 여러 세션에 걸쳐 지속적으로 정보를 저장하는 기억  | 장기간·영구 | DB, 지식 그래프, 벡터 DB | 개인화 어시스턴트, 고객 지원 | 관리·거버넌스 필요           |
| 에피소드 기억     | 과거의 특정 사건과 경험을 구조화해 저장       | 사건 단위  | 이벤트 로그, 사례 기록     | 사례 기반 추론, 로보틱스   | 일반화에 한계              |
| 의미 기억       | 사실·정의·규칙 등 일반화된 지식           | 지속적    | 지식 베이스, 임베딩       | 법률·의료·기업 지식 AI   | 최신성 유지 필요            |
| 절차 기억       | 학습된 행동·기술·작업 순서              | 지속적    | 강화학습 정책, 워크플로     | 자동화, 반복 작업 최적화   | 유연성 제한 가능            |

## AI 에이전트 계획

AI 에이전트 계획은 인공 지능(AI) 에이전트가 특정 목표를 달성하기 위한 일련의 행동을 결정하는 과정입니다.

### AI 에이전트 계획의 작동 방식

- **목표 정의**: 에이전트가 도달해야 할 최종 상태를 명확히 규정하여 모든 의사 결정과 계획의 기준점을 제공한다.
- **상태 표현**: 환경, 제약, 맥락을 구조화된 상태로 모델링하여 현재 상황을 정확히 이해하고 예측 가능하게 만든다.
- **행동 순서화**: 현재 상태에서 목표 상태로 이동하기 위한 행동들을 논리적·효율적인 순서로 조직한다.
    - **추론 프레임워크**: ReAct, ReWOO 등의 방식으로 목표 달성을 위한 단계적 또는 계획 기반 추론을 수행한다.
- **최적화 및 평가**: 시간·자원·위험·보상 등을 기준으로 가장 효율적인 행동 계획을 선택한다.
    - **휴리스틱 검색**: 목표와의 거리 추정을 통해 빠르게 근사 최적 경로를 찾는다.
    - **강화 학습**: 보상과 페널티를 통해 시행착오 기반으로 행동 전략을 지속적으로 개선한다.
    - **확률적 계획**: 불확실한 환경에서 여러 결과의 가능성을 고려해 기대 효용이 가장 높은 행동을 선택한다.
- **협업**: 다중 에이전트가 목표와 정보를 공유·조정하며 중앙화 또는 분산 방식으로 공동 계획을 수행한다.

### 계획 후

AI 솔루션은 설계에 따라 달라질 수 있지만, 전형적인 에이전틱 워크플로에서는 계획 후 다음 단계가 행동 실행입니다.

이 단계에서 에이전트는 계획에 정의된 행동을 수행합니다.

이는 작업을 수행하고 검색 보강 생성(RAG), 툴 사용 및 기능 호출(도구 호출)을 통해 외부 시스템이나 지식 기반과 상호 작용하는 것을 포함합니다.

## 도구 호출

도구 호출은 인공 지능(AI) 모델이 외부 도구, 애플리케이션 프로그래밍 인터페이스(API) 또는 시스템과 상호 작용하여 기능을 향상시키는 능력을 말합니다.

### 도구 호출이 중요한 이유

* **LLM은 원래 정적인 지식만 가진다**

  → 학습 시점 이후의 정보, 실시간 데이터는 모른다

* **현실 문제는 실시간·외부 정보가 필요하다**

  → 최신 뉴스, 주가, 사용자 데이터, 계산 결과 등

* **도구 호출은 LLM의 ‘손과 눈’ 역할을 한다**

  → API, DB, 외부 시스템에 직접 물어볼 수 있게 함

* **정확성과 신뢰성이 크게 올라간다**

  → 추측이 아니라 실제 데이터를 기반으로 응답

* **LLM을 ‘말하는 모델’에서 ‘일하는 에이전트’로 바꾼다**

  → 조회, 계산, 실행까지 가능

아래처럼 **리스트 형태로 아주 정리해서** 정리할게요.

---

### 도구 호출 작동 방식 (Step-by-step)

1. **도구 필요성 인식**

    * LLM이 자신의 내부 지식만으로는 답할 수 없음을 판단
    * 실시간 데이터·외부 계산·시스템 연동이 필요하다고 인식

2. **도구 선택**

    * 날씨 API, 데이터베이스, 계산 서비스 등 가장 적절한 도구 선택
    * 각 도구의 이름, 설명, 입력/출력 스키마를 기준으로 결정

3. **인수(args) 결정**

    * 도구 실행에 필요한 파라미터를 구조화된 형태로 준비
    * 자연어 요청 → 정형 입력으로 변환

4. **쿼리 생성**

    * 선택된 도구가 이해할 수 있는 요청 포맷(API 스펙)에 맞춰 쿼리 구성

5. **쿼리 전송**

    * HTTP 요청 등으로 외부 API 호출
    * 필요 시 API Key, 인증 정보 포함

6. **응답 수신**

    * 외부 도구가 JSON 등 기계 친화적 형식으로 결과 반환

7. **응답 파싱 및 처리**

    * 필요한 정보만 추출하고 불필요한 데이터 제거
    * 사용자에게 전달할 형태로 재구성

8. **결과 제시 또는 액션 수행**

    * 자연어 응답으로 설명
    * 또는 예약, 실행, 저장 등 실제 작업 수행

9. **재질의 및 구체화 (선택)**

    * 사용자의 추가 요청에 따라 다시 도구 호출
    * 응답을 점진적으로 세분화

### 도구 호출 유형

| 도구 호출 유형       | 설명                             | 대표 활용 사례                |
|----------------|--------------------------------|-------------------------|
| 정보 조회 및 검색     | 웹·뉴스·학술·금융 등 외부 소스에서 실시간 정보 조회 | 주가 조회, 최신 뉴스, 논문 검색     |
| 코드 실행          | 외부 계산 엔진이나 실행 환경을 통해 코드·수식 실행  | 수학 계산, 시뮬레이션, Python 실행 |
| 프로세스 자동화       | 외부 서비스와 연동해 반복 업무 자동 처리        | 일정 예약, 이메일 발송, CRM 업데이트 |
| 스마트 디바이스 / IoT | IoT·로봇·디바이스 상태 모니터링 및 제어       | 홈 자동화, 산업 설비 제어         |
| 시스템 연동 액션      | 기업 시스템과 직접 상호작용하여 상태 변경        | 결제 처리, 주문 생성, 재고 수정     |

## AI 에이전트 통신 (켜뮤니케이션)

AI 에이전트 통신은 인공 지능 에이전트가 서로, 인간 또는 외부 시스템과 상호 작용하여 정보를 교환하고, 의사 결정을 내리고, 작업을 완료하는 방식을 말합니다.

### AI 에이전트 통신 유형

| 통신 유형                     | 설명                          | 주요 기술 / 프로토콜      | 특징                  | 활용 사례                 |
|---------------------------|-----------------------------|-------------------|---------------------|-----------------------|
| 에이전트 간 통신 (Agent ↔ Agent) | 여러 AI 에이전트가 정보를 공유하고 협력·협상  | KQML, FIPA-ACL    | 고속·정확한 정보 교환, 협업 중심 | 다중 에이전트 시스템, 분산 문제 해결 |
| 중앙 집중식 통신                 | 단일 AI가 데이터를 처리해 다른 에이전트에 배포 | 중앙 컨트롤러, 오케스트레이터  | 관리 용이, 병목 가능        | 중앙 플래너 기반 MAS         |
| 분산(P2P) 통신                | 에이전트들이 직접 상호 작용하며 결정        | P2P 메시징           | 확장성·탄력성 우수          | 자율 드론 군집              |
| 암묵적 통신                    | 직접 메시지 없이 행동·상태 관찰로 정보 교환   | 상태 관찰, 환경 피드백     | 오버헤드 적음             | 로보틱 협업                |
| 인간-AI 통신                  | 인간과 자연어·음성·시각 인터페이스로 소통     | NLP, ASR, 멀티모달 UI | 직관적 상호작용            | 챗봇, 음성 비서             |

### AI 에이전트 통신의 과제

| 과제           | 설명                          | 주요 영향            | 대표 사례                 |
|--------------|-----------------------------|------------------|-----------------------|
| 표준화된 프로토콜 부재 | 플랫폼마다 서로 다른 통신 규약·데이터 형식 사용 | 상호 운용성 저하, 통신 오류 | 스마트 시티 교통 시스템 ↔ 자율주행차 |
| 모호성과 오해      | 메시지 의미가 불명확해 잘못 해석 가능       | 잘못된 조치, 고객 불만    | “주문을 변경하고 싶어요” 오해     |
| 지연 시간        | 네트워크·연산 지연으로 실시간 대응 어려움     | 즉각적 의사결정 실패      | 자율주행차 센서 데이터 지연       |
| 보안 및 개인정보 보호 | 통신 중 데이터 탈취·조작 위험           | 시스템 장애, 신뢰성 저하   | 의료 AI 진단 데이터 변조       |
| 확장성          | 에이전트 수 증가로 통신 오버헤드 증가       | 성능 저하, 네트워크 정체   | 대규모 금융 거래 봇           |
| 적응성          | 동적 환경 변화에 통신 전략 미흡          | 의사결정 중단          | 재난 대응 드론·로봇           |
| 인간 언어 이해     | 의도·정서·뉘앙스 해석의 어려움           | 오해된 응답           | “여기 얼어 죽겠어” 발언        |

## 러닝

AI 에이전트 학습이란 인공 지능(AI) 에이전트가 환경과 상호 작용하고, 데이터를 처리하고, 의사 결정을 최적화하면서 점차적으로 성능을 개선하는 과정을 말합니다.

이 학습 과정을 통해 자율 에이전트는 동적 환경에 적응하고 효율성을 개선하며 복잡한 작업을 처리합니다.

학습 에이전트는 일반적으로 다음과 같은 4가지 주요 구성 요소로 구성됩니다.

| 구성 요소  | 역할                | 핵심 기능                         |
|--------|-------------------|-------------------------------|
| 성능 요소  | 현재 지식을 바탕으로 행동 결정 | 환경 인식 → 의사 결정 → 행동 실행         |
| 학습 요소  | 경험과 피드백으로 지식 개선   | 정책·모델 업데이트, 성능 향상             |
| 비판자    | 행동 결과를 평가         | 보상·페널티 제공, 목표 대비 성과 측정        |
| 문제 생성기 | 탐색적 과제 제안         | 새로운 전략 발견, 탐험(Exploration) 유도 |

### AI 에이전트 학습 유형

| 학습 유형      | 핵심 개념           | 학습 방식        | 주요 활용 사례             | 특징                  |
|------------|-----------------|--------------|----------------------|---------------------|
| 지도 학습      | 레이블이 있는 데이터로 학습 | 입력–정답 쌍 학습   | 챗봇 응답, 이미지 인식, 의료 진단 | 정확도 높음, 데이터 준비 비용 큼 |
| 비지도 학습     | 레이블 없이 패턴 발견    | 군집화·이상 탐지    | 고객 세분화, 추천 시스템, 보안   | 숨은 구조 발견, 해석 난이도    |
| 자기 지도 학습   | 데이터 자체에서 레이블 생성 | 비정형 데이터 활용   | NLP, 컴퓨터 비전          | 대규모 데이터에 적합         |
| 강화 학습      | 보상 기반 시행착오 학습   | 상태–행동–보상 반복  | 자율주행, 게임, 대화 최적화     | 장기 보상 최적화, 학습 비용 큼  |
| 지속적 학습     | 학습을 멈추지 않고 업데이트 | 신규 데이터 지속 반영 | 실시간 시스템, 변화 환경       | 치명적 망각 방지           |
| 다중 에이전트 학습 | 여러 에이전트 협력·경쟁   | 지식 공유·경쟁 전략  | 로봇 군집, 금융 거래         | 확장성·적응성 우수          |

### 피드백 메커니즘

| 피드백 유형       | 피드백 형태       | 작동 방식                   | 대표 알고리즘 / 예시                | 특징                   |
|--------------|--------------|-------------------------|-----------------------------|----------------------|
| 비지도 학습 피드백   | 암시적 피드백      | 데이터 내부의 구조·패턴을 기준으로 최적화 | 클러스터링, 오토인코더                | 명시적 정답 없음, 구조 발견에 강함 |
| 지도 학습 피드백    | 명시적 레이블      | 예측값과 실제 레이블 간 오류 계산     | 분류·회귀, 추천 시스템               | 정확도 높음, 휴먼 인 더 루프    |
| 강화 학습 피드백    | 보상 / 페널티     | 행동 결과에 대한 스칼라 보상 제공     | Q-learning, Policy Gradient | 순차적 의사결정, 장기 보상 최적화  |
| 자기 지도 학습 피드백 | 자체 생성 레이블    | 데이터 일부로 다른 부분 예측        | Masked LM, 미래 프레임 예측        | 대규모 비정형 데이터에 적합      |
| 실시간 피드백      | 즉각적 센서·상태 정보 | 행동 직후 환경 반응 반영          | 자율주행, RPA                   | 동적 환경 적응에 필수         |

## 에이전트 워크플로

에이전틱 워크플로는 자율적인 AI 에이전트가 최소한의 인간 개입으로 결정을 내리고, 조치를 취하고, 작업을 조정하는 AI 기반 프로세스입니다.

아래는 **에이전트 워크플로가 어떻게 작동하는지**를 **단계별 리스트**로 정리한 것입니다.

### 에이전트 워크플로 동작 방식 (Agentic Workflow)

1. **문제 입력**

    * 사용자가 문제를 자연어로 보고
    * 예: “내 Wi-Fi가 작동하지 않습니다”

2. **문제 이해**

    * AI 에이전트가 추가 질문을 통해 맥락 수집
    * 예: 다른 기기는 연결되는지, 최근 변경 사항이 있는지

3. **진단 단계 실행**

    * 수집된 정보를 바탕으로 가능한 원인 가설 수립
    * 네트워크 상태 확인, 로그 점검, 설정 점검 등 수행

4. **적응형 도구 사용**

    * 필요에 따라 외부 도구·API 호출
    * 서버 모니터링, 스크립트 실행, 설정 리셋 등

5. **결과 평가**

    * 실행 결과가 문제를 해결했는지 판단
    * 성공 / 부분 성공 / 실패 구분

6. **반복 및 전략 조정**

    * 실패 시 다른 접근 방식 선택
    * 추가 진단, 대안 해결책 제안, 경로 재탐색

7. **종결 또는 에스컬레이션**

    * 해결되면 워크플로 종료
    * 해결되지 않으면 시도 내역을 정리해 인간 담당자에게 전달

8. **학습 및 기록**

    * 성공·실패 사례를 지식으로 저장
    * 다음 유사 문제에서 더 빠르고 정확하게 대응

### 에이전틱 워크플로의 구성 요소

| 구성 요소            | 역할         | 핵심 설명                                |
|------------------|------------|--------------------------------------|
| AI 에이전트          | 워크플로의 주체   | 사용자 또는 시스템을 대신해 계획·의사결정·실행을 자율적으로 수행 |
| 대규모 언어 모델(LLM)   | 인지·추론 엔진   | 자연어 이해·생성 담당, 온도 등 파라미터로 출력 품질 조절    |
| 도구 (Tools)       | 외부 세계와의 연결 | API, 웹 검색, 데이터베이스 등을 통해 실시간·외부 정보 활용 |
| 피드백 메커니즘         | 품질 제어 장치   | HITL 또는 다른 에이전트 피드백으로 의사결정과 결과 개선    |
| 프롬프트 엔지니어링       | 추론 유도 장치   | CoT, 제로샷, 원샷, 자기 성찰 등으로 모델 이해도 향상    |
| 다중 에이전트 협업       | 복잡도 분산     | 각 에이전트가 전문 영역을 맡아 지식 공유·협력           |
| 통합 (Integration) | 실무 연결 고리   | 기존 인프라·데이터·에이전트 프레임워크와 연동            |
