{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 실습: Q&A 애플리케이션"
      ],
      "metadata": {
        "id": "l7RRm8sWHDUj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChian과 LangGraph 설치"
      ],
      "metadata": {
        "id": "rULFzNzOG3yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.3.0 langchain-openai==0.2.0 langgraph==0.2.22"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WiMGNkSJHrQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI API 키 설정"
      ],
      "metadata": {
        "id": "ZjzL_PmRIwvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = userdata.get('LANGSMITH_TRACING')\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = userdata.get('LANGSMITH_ENDPOINT')\n",
        "os.environ['LANGCHAIN_API_KEY'] = userdata.get('LANGSMITH_API_KEY')\n",
        "os.environ['LANGCHAIN_PROJECT'] = userdata.get('LANGSMITH_PROJECT')"
      ],
      "metadata": {
        "id": "T5zEU6irH6E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "역할 정의"
      ],
      "metadata": {
        "id": "pU0YHPmLIq18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROLES = {\n",
        "    \"1\": {\n",
        "        \"name\": \"일반 지식 전문가\",\n",
        "        \"description\": \"폭넓은 분야의 일반적인 질문에 답변\",\n",
        "        \"details\": \"폭넓은 분야의 일반적인 질문에 대해 정확하고 이해하기 쉬운 답변을 제공하세요.\"\n",
        "    },\n",
        "    \"2\": {\n",
        "        \"name\": \"생성형 AI 제품 전문가\",\n",
        "        \"description\": \"생성형 AI와 관련 제품, 기술에 관한 전문적인 질문에 답변\",\n",
        "        \"details\": \"생성형 AI와 관련 제품, 기술에 관한 전문적인 질문에 대해 최신 정보와 깊은 통찰력을 제공하세요.\"\n",
        "    },\n",
        "    \"3\": {\n",
        "        \"name\": \"카운슬러\",\n",
        "        \"description\": \"개인적인 고민이나 심리적인 문제에 대해 지원 제공\",\n",
        "        \"details\": \"개인적인 고민이나 심리적인 문제에 대해 공감적이고 지원적인 답변을 제공하고, 가능하다면 적절한 조언도 해주세요.\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "rYk1s4o9I6sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "스테이트 정의"
      ],
      "metadata": {
        "id": "0J2Zt93YJDoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "class State(BaseModel):\n",
        "  query: str = Field(..., description=\"사용자의 질문\")\n",
        "  current_role: str = Field(default=\"\", description=\"선정된 답변 역할\")\n",
        "  messages: Annotated[list[str], operator.add] = Field(default=[],description=\"답변 이력\")\n",
        "  current_judge: bool = Field(default=False, description=\"품질 체크 결과\")\n",
        "  judgement_reason: str = Field(default=\"\", description=\"품질 체크 판정 이유\")"
      ],
      "metadata": {
        "id": "k33xn9C0oxVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chat model 초기화"
      ],
      "metadata": {
        "id": "NJ4xFLkVqSug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
        "# 나중에 max_tokens 값을 변경할 수 있도록 변경 가능한 필드 선언\n",
        "llm = llm.configurable_fields(max_tokens=ConfigurableField(id='max_tokens'))"
      ],
      "metadata": {
        "id": "uzy9nsh0qW6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "노드 정의"
      ],
      "metadata": {
        "id": "uf5YVksArACB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def selection_node(state: State) -> dict[str, Any]:\n",
        "  query = state.query\n",
        "  role_options = \"\\n\".join([f\"{k}. {v['name']}: {v['description']}\" for k, v in ROLES.items()])\n",
        "\n",
        "  prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "  질문을 분석하고, 가장 적절한 답변 담당 역할을 선택하세요.\n",
        "  선택지:\n",
        "  {role_options}\n",
        "\n",
        "  답변은 선택지의 번호{{1, 2, 또는 3}}만 반환하세요.\n",
        "\n",
        "  질문: {query}\n",
        "  \"\"\".strip())\n",
        "\n",
        "  # 선택지의 번호만 반환하기를 기대하므로 max_tokens 값을 1로 변경\n",
        "  chain = prompt | llm.with_config(configurable=dict(max_tokens=1)) | StrOutputParser()\n",
        "  role_number = chain.invoke({\"role_options\": role_options, \"query\": query})\n",
        "  selected_role = ROLES[role_number.strip()][\"name\"]\n",
        "\n",
        "  return {\"current_role\": selected_role}"
      ],
      "metadata": {
        "id": "PgeHK_2wrFeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "answering 노드 구현"
      ],
      "metadata": {
        "id": "08PsSYXbsdjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answering_node(state: State) -> dict[str, Any]:\n",
        "  query = state.query\n",
        "  role = state.current_role\n",
        "  role_details = \"\\n\".join([f\"- {v['name']}: {v['details']}\" for v in ROLES.values()])\n",
        "  prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "  당신은 {role}로서 답변하세요. 다음 질문에 대해 당신의 역할에 기반한 적잘한 답변을 제공하세요.\n",
        "\n",
        "  역할 상세:\n",
        "  {role_details}\n",
        "\n",
        "  질문: {query}\n",
        "\n",
        "  답변:\"\"\".strip()\n",
        "  )\n",
        "  chain = prompt | llm | StrOutputParser()\n",
        "  answer = chain.invoke({\"role\": role, \"role_details\": role_details, \"query\": query})\n",
        "  return {\"messages\": [answer]}"
      ],
      "metadata": {
        "id": "Bm1uc1KYsrvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check 노드 구현"
      ],
      "metadata": {
        "id": "wF2gVybQtfMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Judgement(BaseModel):\n",
        "  judge: bool = Field(default=False, description=\"판정 결과\")\n",
        "  reason: str = Field(default=\"\", description=\"판정 이유\")\n",
        "\n",
        "def check_node(state: State) -> dict[str, Any]:\n",
        "  query = state.query\n",
        "  answer = state.messages[-1]\n",
        "  prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "  다음 답변의 품질을 체크하고, 문제가 있으면 'False', 문제가 없으면 'True'로 답변하세요.\n",
        "  또한, 그 판정 이유도 설명하세요.\n",
        "\n",
        "  사용자의 질문: {query}\n",
        "  답변: {answer}\n",
        "  \"\"\".strip()\n",
        "  )\n",
        "  chain = prompt | llm.with_structured_output(Judgement)\n",
        "  result: Judgement = chain.invoke({\"query\": query, \"answer\": answer})\n",
        "\n",
        "  return {\n",
        "      \"current_judge\": result.judge,\n",
        "      \"judgement_reason\": result.reason\n",
        "  }"
      ],
      "metadata": {
        "id": "Pw0AEELjtiiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래프 생성"
      ],
      "metadata": {
        "id": "s8lS_nbtuqHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph\n",
        "\n",
        "workflow = StateGraph(State)"
      ],
      "metadata": {
        "id": "zzqYtFq6utSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "노드 추가"
      ],
      "metadata": {
        "id": "MstWYqb3u1VZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.add_node(\"selection\", selection_node)\n",
        "workflow.add_node(\"answering\", answering_node)\n",
        "workflow.add_node(\"check\",check_node)"
      ],
      "metadata": {
        "id": "6qNp-RSWu4zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "에지 정의"
      ],
      "metadata": {
        "id": "X015yBiWvCeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# selection 노드에서 처리 시작\n",
        "workflow.set_entry_point(\"selection\")\n",
        "\n",
        "# selection 노드에서 answering 노드로\n",
        "workflow.add_edge(\"selection\", \"answering\")\n",
        "\n",
        "# answering 노드에서 check 노드로\n",
        "workflow.add_edge(\"answering\", \"check\")"
      ],
      "metadata": {
        "id": "aimEPIAVvHYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "조건부 에지 정의"
      ],
      "metadata": {
        "id": "Ciylytyzvay5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END\n",
        "\n",
        "# check 노드에서 다음 노드로의 전환에 조건부 에지 정의\n",
        "# state.current_judge 값이 True면 END 노드로, False면 selection 노드로\n",
        "workflow.add_conditional_edges(\n",
        "    \"check\",\n",
        "    lambda state: state.current_judge,\n",
        "    {True: END, False: \"selection\"}\n",
        ")"
      ],
      "metadata": {
        "id": "tINdbVqdvedl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래프 컴파일"
      ],
      "metadata": {
        "id": "l5zGbXThv8xR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compiled = workflow.compile()"
      ],
      "metadata": {
        "id": "0XSeY4uvwA5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래프 실행"
      ],
      "metadata": {
        "id": "3hOCz9rSwEeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_state = State(query=\"생성형 AI에 관해 알려주세요\")\n",
        "result = compiled.invoke(initial_state)"
      ],
      "metadata": {
        "id": "Rr4GLBfQwGi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과 표시"
      ],
      "metadata": {
        "id": "qar719q6wSKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[\"messages\"][-1])"
      ],
      "metadata": {
        "id": "8yi8854wx_KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래프 구조 시각화 표시"
      ],
      "metadata": {
        "id": "x6b_KulayEdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install graphviz libgraphviz-dev pkg-config\n",
        "!pip install pygraphviz"
      ],
      "metadata": {
        "collapsed": true,
        "id": "n2wuETh9yjOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(compiled.get_graph().draw_png())"
      ],
      "metadata": {
        "id": "Z_-egstwyuQX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}